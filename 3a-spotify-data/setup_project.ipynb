{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Data Download and Extraction\n",
    "\n",
    "This script downloads a ZIP file from Google Drive, stores it in a structured directory, and extracts its contents into a specific location.\n",
    "\n",
    "## Directory Structure\n",
    "\n",
    "```\n",
    "project_root/\n",
    "â”‚â”€â”€ data/\n",
    "â”‚   â”‚â”€â”€ download/data.zip   # Contains the downloaded ZIP file\n",
    "â”‚   â”‚â”€â”€ csv_files/          # Contains extracted CSV files\n",
    "â”‚â”€â”€ setup_project.ipynb     # Jupyter Notebook for downloading and extracting data\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gdown\n",
    "import zipfile\n",
    "\n",
    "# Define directories\n",
    "data_dir = \"data\"\n",
    "download_dir = os.path.join(data_dir, \"download\")\n",
    "csv_dir = os.path.join(data_dir, \"csv_files\")\n",
    "\n",
    "\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "os.makedirs(csv_dir, exist_ok=True)\n",
    "\n",
    "zip_path = os.path.join(download_dir, \"data.zip\")\n",
    "\n",
    "# Download ZIP file from Google Drive\n",
    "url = f\"https://drive.google.com/uc?id=1H_T6Z74iMs0_VXMSD7wwcQ_ctB5kalNg\"\n",
    "gdown.download(url, zip_path, quiet=False)\n",
    "\n",
    "# Extract ZIP file into csv_files directory\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(csv_dir)\n",
    "\n",
    "print(\"Download and extraction complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_albums = pd.read_csv('./data/csv_files/SpotGenTrack/Data Sources/spotify_albums.csv')\n",
    "df_tracks = pd.read_csv('./data/csv_files/SpotGenTrack/Data Sources/spotify_tracks.csv')\n",
    "df_artists = pd.read_csv('./data/csv_files/SpotGenTrack/Data Sources/spotify_artists.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ² Random Track Recommender using scikit-learn DummyClassifier\n",
    "\n",
    "create a simple random track recommender using scikit-learnâ€™s `DummyClassifier`. \n",
    "The model is trained on track names from `df_tracks['name']`, and provides random recommendations regardless of the input.\n",
    "\n",
    "### ðŸ”¹ Step 1: Import and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Use track names as both input and target (since it's random anyway)\n",
    "X = df_tracks[['name']]  \n",
    "y = df_tracks['name']    \n",
    "\n",
    "# Create a DummyClassifier that selects output uniformly at random\n",
    "model = DummyClassifier(strategy='uniform', random_state=42)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model ignores the input and randomly selects one of the known tracks from the training set. This simulates a random discovery mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Search for a track name\n",
    "search_term = \"highway\"\n",
    "\n",
    "# Step 2: Find all matches\n",
    "matches = df_tracks[df_tracks['name'].str.contains(search_term, case=False, na=False)]\n",
    "matches[['id', 'name', 'artists_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_track = [[matches['name'].iloc[0]]]\n",
    "prediction = model.predict(input_track)\n",
    "\n",
    "print(f\"\\nRandom recommendation based on '{input_track[0][0]}' -> {prediction[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store model as file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(model, open(\"dummy_model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "loaded_model = pickle.load(open(\"dummy_model.pkl\", \"rb\"))\n",
    "# Use the loaded model to make predictions\n",
    "loaded_prediction = loaded_model.predict(input_track)\n",
    "print(f\"\\nLoaded model prediction based on '{input_track[0][0]}' -> {loaded_prediction[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
